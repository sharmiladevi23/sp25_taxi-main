{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4aba119e-8624-4c30-ad3c-49759f3f18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e63f45f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timedelta in /opt/anaconda3/lib/python3.12/site-packages (2020.12.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d70f3626-766c-430f-97d9-ee5c9068c240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 22:56:38.105797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "current_date = pd.to_datetime(datetime.utcnow())\n",
    "print(f\"{current_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98019378-2d7e-44d9-b6a3-794e640b2910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dfe29a0-f439-4e3b-8ad2-78eb40a3bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "current_date = pd.to_datetime(datetime.now(timezone.utc)).floor(\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1ceac31-828d-4ca3-9ae3-19a0f4ec2ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2025-03-04T22:00:00.000000000')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_date.to_datetime64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bccd923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_data_to = current_date\n",
    "fetch_data_from = current_date - timedelta(days=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "133fcfda-af02-43f0-8851-63ef10b778ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-03-04 22:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_data_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec2f9e79-58b1-4e18-9346-c93fc04e1f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-02-03 22:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_data_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfaf545c-01d6-41dc-871d-c514c667bbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom datetime import datetime, timedelta\\nfrom typing import Union\\nimport pandas as pd\\nfrom src.data_utils import load_and_process_taxi_data\\n\\ndef fetch_batch_raw_data(from_date: Union[datetime, str], to_date: Union[datetime, str]) -> pd.DataFrame:\\n    \\n    Simulate production data by sampling historical data from 52 weeks ago (i.e., 1 year).\\n\\n    Args:\\n        from_date (datetime or str): The start date for the data batch.\\n        to_date (datetime or str): The end date for the data batch.\\n\\n    Returns:\\n        pd.DataFrame: A DataFrame containing the simulated production data.\\n    \\n    # Convert string inputs to datetime if necessary\\n    from_date = pd.to_datetime(from_date)\\n    to_date = pd.to_datetime(to_date)\\n\\n    # Ensure timezone consistency (convert naive timestamps to UTC)\\n    if from_date.tz is None:\\n        from_date = from_date.tz_localize(\"UTC\")\\n    else:\\n        from_date = from_date.tz_convert(\"UTC\")\\n\\n    if to_date.tz is None:\\n        to_date = to_date.tz_localize(\"UTC\")\\n    else:\\n        to_date = to_date.tz_convert(\"UTC\")\\n\\n    # Validate input dates\\n    if from_date >= to_date:\\n        raise ValueError(\"\\'from_date\\' must be earlier than \\'to_date\\'.\")\\n\\n    # Shift dates back by 52 weeks (1 year)\\n    historical_from_date = from_date - timedelta(weeks=52)\\n    historical_to_date = to_date - timedelta(weeks=52)\\n\\n    # Load and filter data for the historical period\\n    rides_from = load_and_process_taxi_data(year=historical_from_date.year, months=[historical_from_date.month])\\n    rides_from = rides_from[rides_from.pickup_datetime >= historical_from_date]\\n\\n    if historical_to_date.month != historical_from_date.month:\\n        rides_to = load_and_process_taxi_data(year=historical_to_date.year, months=[historical_to_date.month])\\n        rides_to = rides_to[rides_to.pickup_datetime < historical_to_date]\\n        # Combine the filtered data\\n        rides = pd.concat([rides_from, rides_to], ignore_index=True)\\n    else:\\n        rides = rides_from\\n\\n    # Ensure \\'pickup_datetime\\' is timezone-aware (convert to UTC if necessary)\\n    rides[\\'pickup_datetime\\'] = pd.to_datetime(rides[\\'pickup_datetime\\'])\\n    if rides[\\'pickup_datetime\\'].dt.tz is None:\\n        rides[\\'pickup_datetime\\'] = rides[\\'pickup_datetime\\'].dt.tz_localize(\"UTC\")\\n    else:\\n        rides[\\'pickup_datetime\\'] = rides[\\'pickup_datetime\\'].dt.tz_convert(\"UTC\")\\n\\n    # Shift the data forward by 52 weeks to simulate recent data\\n    rides[\\'pickup_datetime\\'] += timedelta(weeks=52)\\n\\n    # Sort the data for consistency\\n    rides.sort_values(by=[\\'pickup_location_id\\', \\'pickup_datetime\\'], inplace=True)\\n\\n    return rides\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Union\n",
    "import pandas as pd\n",
    "from src.data_utils import load_and_process_taxi_data\n",
    "\n",
    "def fetch_batch_raw_data(from_date: Union[datetime, str], to_date: Union[datetime, str]) -> pd.DataFrame:\n",
    "    \n",
    "    Simulate production data by sampling historical data from 52 weeks ago (i.e., 1 year).\n",
    "\n",
    "    Args:\n",
    "        from_date (datetime or str): The start date for the data batch.\n",
    "        to_date (datetime or str): The end date for the data batch.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the simulated production data.\n",
    "    \n",
    "    # Convert string inputs to datetime if necessary\n",
    "    from_date = pd.to_datetime(from_date)\n",
    "    to_date = pd.to_datetime(to_date)\n",
    "\n",
    "    # Ensure timezone consistency (convert naive timestamps to UTC)\n",
    "    if from_date.tz is None:\n",
    "        from_date = from_date.tz_localize(\"UTC\")\n",
    "    else:\n",
    "        from_date = from_date.tz_convert(\"UTC\")\n",
    "\n",
    "    if to_date.tz is None:\n",
    "        to_date = to_date.tz_localize(\"UTC\")\n",
    "    else:\n",
    "        to_date = to_date.tz_convert(\"UTC\")\n",
    "\n",
    "    # Validate input dates\n",
    "    if from_date >= to_date:\n",
    "        raise ValueError(\"'from_date' must be earlier than 'to_date'.\")\n",
    "\n",
    "    # Shift dates back by 52 weeks (1 year)\n",
    "    historical_from_date = from_date - timedelta(weeks=52)\n",
    "    historical_to_date = to_date - timedelta(weeks=52)\n",
    "\n",
    "    # Load and filter data for the historical period\n",
    "    rides_from = load_and_process_taxi_data(year=historical_from_date.year, months=[historical_from_date.month])\n",
    "    rides_from = rides_from[rides_from.pickup_datetime >= historical_from_date]\n",
    "\n",
    "    if historical_to_date.month != historical_from_date.month:\n",
    "        rides_to = load_and_process_taxi_data(year=historical_to_date.year, months=[historical_to_date.month])\n",
    "        rides_to = rides_to[rides_to.pickup_datetime < historical_to_date]\n",
    "        # Combine the filtered data\n",
    "        rides = pd.concat([rides_from, rides_to], ignore_index=True)\n",
    "    else:\n",
    "        rides = rides_from\n",
    "\n",
    "    # Ensure 'pickup_datetime' is timezone-aware (convert to UTC if necessary)\n",
    "    rides['pickup_datetime'] = pd.to_datetime(rides['pickup_datetime'])\n",
    "    if rides['pickup_datetime'].dt.tz is None:\n",
    "        rides['pickup_datetime'] = rides['pickup_datetime'].dt.tz_localize(\"UTC\")\n",
    "    else:\n",
    "        rides['pickup_datetime'] = rides['pickup_datetime'].dt.tz_convert(\"UTC\")\n",
    "\n",
    "    # Shift the data forward by 52 weeks to simulate recent data\n",
    "    rides['pickup_datetime'] += timedelta(weeks=52)\n",
    "\n",
    "    # Sort the data for consistency\n",
    "    rides.sort_values(by=['pickup_location_id', 'pickup_datetime'], inplace=True)\n",
    "\n",
    "    return rides\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ccc813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing import Union\n",
    "import pandas as pd\n",
    "from src.data_utils import load_and_process_taxi_data\n",
    "\n",
    "def fetch_batch_raw_data(from_date: Union[datetime, str], to_date: Union[datetime, str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simulate production data by sampling historical data from 52 weeks ago (i.e., 1 year).\n",
    "    \"\"\"\n",
    "    # Convert string inputs to datetime if necessary\n",
    "    if isinstance(from_date, str):\n",
    "        from_date = datetime.fromisoformat(from_date)\n",
    "    if isinstance(to_date, str):\n",
    "        to_date = datetime.fromisoformat(to_date)\n",
    "\n",
    "    # Validate input dates\n",
    "    if not isinstance(from_date, datetime) or not isinstance(to_date, datetime):\n",
    "        raise ValueError(\"Both 'from_date' and 'to_date' must be datetime objects or valid ISO format strings.\")\n",
    "    if from_date >= to_date:\n",
    "        raise ValueError(\"'from_date' must be earlier than 'to_date'.\")\n",
    "\n",
    "    # Shift dates back by 52 weeks (1 year)\n",
    "    historical_from_date = from_date - timedelta(weeks=52)\n",
    "    historical_to_date = to_date - timedelta(weeks=52)\n",
    "\n",
    "    # ✅ Ensure datetime is timezone-naive\n",
    "    historical_from_date = pd.to_datetime(historical_from_date).tz_localize(None)\n",
    "    historical_to_date = pd.to_datetime(historical_to_date).tz_localize(None)\n",
    "\n",
    "    # Load and filter data for the historical period\n",
    "    rides_from = load_and_process_taxi_data(year=historical_from_date.year, months=[historical_from_date.month])\n",
    "    \n",
    "    # ✅ Ensure `pickup_datetime` is also timezone-naive\n",
    "    rides_from['pickup_datetime'] = pd.to_datetime(rides_from['pickup_datetime']).dt.tz_localize(None)\n",
    "\n",
    "    # ✅ Apply filtering correctly\n",
    "    rides_from = rides_from[rides_from.pickup_datetime >= historical_from_date]\n",
    "\n",
    "    if historical_to_date.month != historical_from_date.month:\n",
    "        rides_to = load_and_process_taxi_data(year=historical_to_date.year, months=[historical_to_date.month])\n",
    "        rides_to['pickup_datetime'] = pd.to_datetime(rides_to['pickup_datetime']).dt.tz_localize(None)\n",
    "        rides_to = rides_to[rides_to.pickup_datetime < historical_to_date]\n",
    "        rides = pd.concat([rides_from, rides_to], ignore_index=True)\n",
    "    else:\n",
    "        rides = rides_from\n",
    "\n",
    "    # Shift the data forward by 52 weeks to simulate recent data\n",
    "    rides['pickup_datetime'] += timedelta(weeks=52)\n",
    "\n",
    "    # Sort the data for consistency\n",
    "    rides.sort_values(by=['pickup_location_id', 'pickup_datetime'], inplace=True)\n",
    "\n",
    "    return rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e1669d5-cc0b-440b-8e8d-8bb78d16c58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists for 2024-02.\n",
      "Loading data for 2024-02...\n",
      "Total records: 3,007,526\n",
      "Valid records: 2,954,709\n",
      "Records dropped: 52,817 (1.76%)\n",
      "Successfully processed data for 2024-02.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n",
      "File already exists for 2024-03.\n",
      "Loading data for 2024-03...\n",
      "Total records: 3,582,628\n",
      "Valid records: 3,518,066\n",
      "Records dropped: 64,562 (1.80%)\n",
      "Successfully processed data for 2024-03.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n"
     ]
    }
   ],
   "source": [
    "rides = fetch_batch_raw_data(fetch_data_from, fetch_data_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22176c04-e64c-496a-9acd-6a6eb7bc2ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>816246</th>\n",
       "      <td>2025-02-12 16:25:44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122947</th>\n",
       "      <td>2025-02-15 16:56:40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6662</th>\n",
       "      <td>2025-02-04 04:14:50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8263</th>\n",
       "      <td>2025-02-04 06:08:40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76016</th>\n",
       "      <td>2025-02-04 18:17:57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943320</th>\n",
       "      <td>2025-03-04 21:56:22</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940886</th>\n",
       "      <td>2025-03-04 21:56:50</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942068</th>\n",
       "      <td>2025-03-04 21:57:22</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942407</th>\n",
       "      <td>2025-03-04 21:58:49</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939845</th>\n",
       "      <td>2025-03-04 21:59:24</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2991609 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pickup_datetime  pickup_location_id\n",
       "816246  2025-02-12 16:25:44                   2\n",
       "1122947 2025-02-15 16:56:40                   2\n",
       "6662    2025-02-04 04:14:50                   3\n",
       "8263    2025-02-04 06:08:40                   3\n",
       "76016   2025-02-04 18:17:57                   3\n",
       "...                     ...                 ...\n",
       "2943320 2025-03-04 21:56:22                 263\n",
       "2940886 2025-03-04 21:56:50                 263\n",
       "2942068 2025-03-04 21:57:22                 263\n",
       "2942407 2025-03-04 21:58:49                 263\n",
       "2939845 2025-03-04 21:59:24                 263\n",
       "\n",
       "[2991609 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "783eebf6-7c7d-4ef8-9134-a92c87123146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import transform_raw_data_into_ts_data\n",
    "ts_data = transform_raw_data_into_ts_data(rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adbca6ba-f012-4f40-b419-ed620a8e7054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-03 22:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-03 23:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-04 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-04 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-04 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174691</th>\n",
       "      <td>2025-03-04 17:00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174692</th>\n",
       "      <td>2025-03-04 18:00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174693</th>\n",
       "      <td>2025-03-04 19:00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174694</th>\n",
       "      <td>2025-03-04 20:00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174695</th>\n",
       "      <td>2025-03-04 21:00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174696 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pickup_hour  pickup_location_id  rides\n",
       "0      2025-02-03 22:00:00                   2      0\n",
       "1      2025-02-03 23:00:00                   2      0\n",
       "2      2025-02-04 00:00:00                   2      0\n",
       "3      2025-02-04 01:00:00                   2      0\n",
       "4      2025-02-04 02:00:00                   2      0\n",
       "...                    ...                 ...    ...\n",
       "174691 2025-03-04 17:00:00                 263    117\n",
       "174692 2025-03-04 18:00:00                 263    132\n",
       "174693 2025-03-04 19:00:00                 263     99\n",
       "174694 2025-03-04 20:00:00                 263     86\n",
       "174695 2025-03-04 21:00:00                 263     76\n",
       "\n",
       "[174696 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b8f1dc6-46d6-4fad-915b-c8c4c02b9887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 174696 entries, 0 to 174695\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   pickup_hour         174696 non-null  datetime64[ns]\n",
      " 1   pickup_location_id  174696 non-null  int16         \n",
      " 2   rides               174696 non-null  int16         \n",
      "dtypes: datetime64[ns](1), int16(2)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "325cbf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport numpy as np\\nimport pytz\\n\\n# Convert pickup_hour to EST\\nts_data[\"pickup_hour_est\"] = ts_data[\"pickup_hour\"].dt.tz_localize(\"UTC\").dt.tz_convert(\"America/New_York\")\\n\\n# Load the taxi zone lookup CSV file to map location IDs to names\\nlookup_csv_path = \"/Users/sharmilamanoj/Downloads/taxi_zone_lookup.csv\"\\nlocation_lookup = pd.read_csv(lookup_csv_path)\\n\\n# Rename the column for merging consistency\\nlocation_lookup.rename(columns={\"LocationID\": \"pickup_location_id\", \"Zone\": \"pickup_location_name\"}, inplace=True)\\n\\n# Identify top 10 pickup locations by frequency\\ntop_10_locations = ts_data[\"pickup_location_id\"].value_counts().nlargest(10).index\\n\\n# Merge ts_data with the lookup table to get names for the top 10 locations\\nts_data = ts_data.merge(location_lookup[[\"pickup_location_id\", \"pickup_location_name\"]], on=\"pickup_location_id\", how=\"left\")\\n\\n# Keep names only for the top 10 locations, others remain NaN\\nts_data.loc[~ts_data[\"pickup_location_id\"].isin(top_10_locations), \"pickup_location_name\"] = None\\n\\n# Apply FFT to rides data (grouped by pickup location)\\nts_data[\"fft_real\"] = 0.0\\nts_data[\"fft_imag\"] = 0.0\\n\\nfor location in ts_data[\"pickup_location_id\"].unique():\\n    rides_series = ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"rides\"].values\\n    fft_values = np.fft.fft(rides_series)\\n    ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"fft_real\"] = np.real(fft_values)\\n    ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"fft_imag\"] = np.imag(fft_values)\\n\\n# Display the updated DataFrame\\nprint(ts_data.head())  # Print the first few rows\\nts_data.to_csv(\"enhanced_ts_data.csv\", index=False)  # Save the file for review\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "\n",
    "# Convert pickup_hour to EST\n",
    "ts_data[\"pickup_hour_est\"] = ts_data[\"pickup_hour\"].dt.tz_localize(\"UTC\").dt.tz_convert(\"America/New_York\")\n",
    "\n",
    "# Load the taxi zone lookup CSV file to map location IDs to names\n",
    "lookup_csv_path = \"/Users/sharmilamanoj/Downloads/taxi_zone_lookup.csv\"\n",
    "location_lookup = pd.read_csv(lookup_csv_path)\n",
    "\n",
    "# Rename the column for merging consistency\n",
    "location_lookup.rename(columns={\"LocationID\": \"pickup_location_id\", \"Zone\": \"pickup_location_name\"}, inplace=True)\n",
    "\n",
    "# Identify top 10 pickup locations by frequency\n",
    "top_10_locations = ts_data[\"pickup_location_id\"].value_counts().nlargest(10).index\n",
    "\n",
    "# Merge ts_data with the lookup table to get names for the top 10 locations\n",
    "ts_data = ts_data.merge(location_lookup[[\"pickup_location_id\", \"pickup_location_name\"]], on=\"pickup_location_id\", how=\"left\")\n",
    "\n",
    "# Keep names only for the top 10 locations, others remain NaN\n",
    "ts_data.loc[~ts_data[\"pickup_location_id\"].isin(top_10_locations), \"pickup_location_name\"] = None\n",
    "\n",
    "# Apply FFT to rides data (grouped by pickup location)\n",
    "ts_data[\"fft_real\"] = 0.0\n",
    "ts_data[\"fft_imag\"] = 0.0\n",
    "\n",
    "for location in ts_data[\"pickup_location_id\"].unique():\n",
    "    rides_series = ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"rides\"].values\n",
    "    fft_values = np.fft.fft(rides_series)\n",
    "    ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"fft_real\"] = np.real(fft_values)\n",
    "    ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"fft_imag\"] = np.imag(fft_values)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(ts_data.head())  # Print the first few rows\n",
    "ts_data.to_csv(\"enhanced_ts_data.csv\", index=False)  # Save the file for review\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a1c6896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor location in top_10_locations:\\n    rides_series = ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"rides\"].values\\n    \\n    if len(rides_series) > 1:  # Ensure there is more than 1 data point\\n        fft_values = np.fft.fft(rides_series)\\n        ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"fft_real\"] = np.real(fft_values)\\n        ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"fft_imag\"] = np.imag(fft_values)\\n    else:\\n        ts_data.loc[ts_data[\"pickup_location_id\"] == location, [\"fft_real\", \"fft_imag\"]] = np.nan\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for location in top_10_locations:\n",
    "    rides_series = ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"rides\"].values\n",
    "    \n",
    "    if len(rides_series) > 1:  # Ensure there is more than 1 data point\n",
    "        fft_values = np.fft.fft(rides_series)\n",
    "        ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"fft_real\"] = np.real(fft_values)\n",
    "        ts_data.loc[ts_data[\"pickup_location_id\"] == location, \"fft_imag\"] = np.imag(fft_values)\n",
    "    else:\n",
    "        ts_data.loc[ts_data[\"pickup_location_id\"] == location, [\"fft_real\", \"fft_imag\"]] = np.nan\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9c933d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ts_data[[\"pickup_location_id\", \"fft_real\", \"fft_imag\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "caf0cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ts_data[\"pickup_location_id\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b0cbd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "##getting top 10 locations\n",
    "#top_10_locations = ts_data[\"pickup_location_id\"].value_counts().nlargest(10).index\n",
    "#print(top_10_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "981b684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ts_data[ts_data[\"pickup_location_id\"] == 2].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f08a8f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ts_data[\"pickup_location_name\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22f1e8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API Key Loaded Successfully!\n",
      "2025-03-04 18:00:26,363 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-03-04 18:00:26,370 INFO: Initializing external client\n",
      "2025-03-04 18:00:26,371 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-04 18:00:27,020 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214665\n",
      "Logged into Hopsworks: nyc_taxi_proj\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HOPSWORKS_API_KEY\"] = \"jaThBXjYztKj0Mr2.jvcnZsSjp04pK6c4uuSoK7LtNHJOe9EFRZtegX2KXmxrHAv6MGSPiIY6iODgbe8S\"\n",
    "api_key = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv(\"hopsworks.env\")  # Make sure this file exists\n",
    "\n",
    "# Print the API key (for debugging)\n",
    "api_key = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"✅ API Key Loaded Successfully!\")\n",
    "else:\n",
    "    print(\"❌ API Key Not Found. Check .env file.\")\n",
    "\n",
    "import os\n",
    "import hopsworks\n",
    "api_key = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "project = hopsworks.login(api_key_value=api_key)\n",
    "print(\"Logged into Hopsworks:\", project.name)\n",
    "\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "FEATURE_GROUP_NAME = \"time_series_hourly_feature_group\"\n",
    "FEATURE_GROUP_VERSION = 1\n",
    "\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=FEATURE_GROUP_NAME,\n",
    "    version=FEATURE_GROUP_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c2d5acd-0f97-4117-b61d-6135391891db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nimport hopsworks\\n\\n# connect to the project\\nproject = hopsworks.login(\\n    project=config.HOPSWORKS_PROJECT_NAME,\\n    api_key_value=config.HOPSWORKS_API_KEY\\n)\\n\\n# connect to the feature store\\nfeature_store = project.get_feature_store()\\n\\n# connect to the feature group\\nfeature_group = feature_store.get_feature_group(\\n    name=config.FEATURE_GROUP_NAME,\\n    version=config.FEATURE_GROUP_VERSION,\\n)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "import hopsworks\n",
    "\n",
    "# connect to the project\n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value=config.HOPSWORKS_API_KEY\n",
    ")\n",
    "\n",
    "# connect to the feature store\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "# connect to the feature group\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    ")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "259dfaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pickup_hour', 'pickup_location_id', 'rides'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ts_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "257a6bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature('pickup_hour', 'timestamp', None, True, False, None, None, 1402010), Feature('pickup_location_id', 'int', None, True, False, None, None, 1402010), Feature('rides', 'int', None, False, False, None, None, 1402010)]\n"
     ]
    }
   ],
   "source": [
    "print(feature_group.schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbc26ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hsfs.feature import Feature  # Import Feature before using it\n",
    "\n",
    "# feature_store = project.get_feature_store()\n",
    "\n",
    "# # Define the updated feature group with the new schema\n",
    "# new_feature_group = feature_store.create_feature_group(\n",
    "#     name=\"new_fft_ts_data\",\n",
    "#     version=1,  # Update as needed\n",
    "#     description=\"Updated feature group with FFT features and pickup location names\",\n",
    "#     primary_key=[\"pickup_hour\", \"pickup_location_id\"],\n",
    "#     features=[\n",
    "#         Feature(\"pickup_hour\", \"timestamp\"),\n",
    "#         Feature(\"pickup_location_id\", \"int\"),\n",
    "#         Feature(\"rides\", \"int\"),\n",
    "#         Feature(\"pickup_hour_est\", \"timestamp\"),\n",
    "#         Feature(\"pickup_location_name\", \"string\"),\n",
    "#         Feature(\"fft_real\", \"double\"),\n",
    "#         Feature(\"fft_imag\", \"double\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Insert the enhanced dataset\n",
    "# new_feature_group.insert(ts_data, write_options={\"wait_for_job\": False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3093058-9e94-4b49-9ad9-32dace742a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 174696/174696 | Elapsed Time: 00:03 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: time_series_hourly_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1214665/jobs/named/time_series_hourly_feature_group_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('time_series_hourly_feature_group_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.insert(ts_data, write_options={\"wait_for_job\": False})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py311_env)",
   "language": "python",
   "name": "py311_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
